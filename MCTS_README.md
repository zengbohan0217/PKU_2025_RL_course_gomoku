# MCTS + LLM Hybrid Agent for Gomoku

## æ¦‚è¿°

è¿™ä¸ªåˆ†æ”¯å®ç°äº†ä¸€ä¸ªåˆ›æ–°çš„äº”å­æ£‹AIAgentï¼Œç»“åˆäº†ï¼š
1. **è’™ç‰¹å¡æ´›æ ‘æœç´¢ (MCTS)** - ç»å…¸æ¸¸æˆAIç®—æ³•ï¼Œç³»ç»ŸåŒ–åœ°æ¢ç´¢æ¸¸æˆæ ‘
2. **å¤§è¯­è¨€æ¨¡å‹ (LLM)** - ç”¨äºæˆ˜ç•¥å±€é¢è¯„ä¼°ï¼Œæä¾›äººç±»çº§åˆ«çš„æ£‹æ„Ÿ

## æ ¸å¿ƒåˆ›æ–°ç‚¹

### 1. æ··åˆæ¶æ„
ä¼ ç»ŸMCTSä½¿ç”¨éšæœºæ¨¡æ‹Ÿæ¥è¯„ä¼°å±€é¢ï¼Œè€Œæˆ‘ä»¬çš„å®ç°ä½¿ç”¨LLMæ¥è¯„ä¼°ä½ç½®ä»·å€¼ï¼Œç»“åˆäº†ï¼š
- **MCTSçš„ç³»ç»Ÿæ€§æœç´¢èƒ½åŠ›** - ä¿è¯ä¸ä¼šé—æ¼é‡è¦å˜åŒ–
- **LLMçš„æˆ˜ç•¥ç†è§£èƒ½åŠ›** - æä¾›æ›´å‡†ç¡®çš„å±€é¢è¯„ä¼°

### 2. ç®—æ³•æµç¨‹

```
å¼€å§‹ MCTS å¾ªç¯ (Næ¬¡æ¨¡æ‹Ÿ)
â”‚
â”œâ”€ Selection (é€‰æ‹©)
â”‚  â””â”€ ä½¿ç”¨ UCB1 å…¬å¼é€‰æ‹©æœ€æœ‰æ½œåŠ›çš„èŠ‚ç‚¹
â”‚
â”œâ”€ Expansion (æ‰©å±•)
â”‚  â””â”€ ä¸ºé€‰ä¸­èŠ‚ç‚¹æ·»åŠ æ–°çš„å­èŠ‚ç‚¹
â”‚
â”œâ”€ Simulation (æ¨¡æ‹Ÿ)
â”‚  â”œâ”€ ä¼ ç»Ÿæ–¹æ³•: éšæœºèµ°å­ç›´åˆ°ç»ˆå±€
â”‚  â””â”€ æˆ‘ä»¬çš„æ–¹æ³•: è°ƒç”¨LLMè¯„ä¼°å½“å‰å±€é¢ä»·å€¼ âœ¨
â”‚
â””â”€ Backpropagation (å›ä¼ )
   â””â”€ å°†è¯„ä¼°ç»“æœå‘ä¸Šä¼ æ’­æ›´æ–°æ‰€æœ‰ç¥–å…ˆèŠ‚ç‚¹
```

### 3. UCB1 å…¬å¼

èŠ‚ç‚¹é€‰æ‹©ä½¿ç”¨ UCB1 (Upper Confidence Bound) å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ï¼š

```
UCB(node) = Q(node)/N(node) + c * sqrt(ln(N(parent)) / N(node))
```

å…¶ä¸­ï¼š
- `Q(node)`: èŠ‚ç‚¹ç´¯ç§¯ä»·å€¼
- `N(node)`: èŠ‚ç‚¹è®¿é—®æ¬¡æ•°
- `c`: æ¢ç´¢æƒé‡ (é»˜è®¤ âˆš2 â‰ˆ 1.41)

## æ–‡ä»¶ç»“æ„

```
PKU_2025_RL_course_gomoku/
â”œâ”€â”€ methods/
â”‚   â”œâ”€â”€ mcts_agent.py          # æ ¸å¿ƒå®ç°
â”‚   â”‚   â”œâ”€â”€ MCTSNode           # MCTSæ ‘èŠ‚ç‚¹
â”‚   â”‚   â”œâ”€â”€ LLMPositionEvaluator  # LLMè¯„ä¼°å™¨
â”‚   â”‚   â””â”€â”€ MCTSLLMAgent       # æ··åˆAgentä¸»ç±»
â”‚   â””â”€â”€ ...
â”œâ”€â”€ run_mcts_demo.py           # æ¼”ç¤ºè„šæœ¬
â””â”€â”€ MCTS_README.md            # æœ¬æ–‡æ¡£
```

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ä½¿ç”¨

```python
from methods.mcts_agent import MCTSLLMAgent

# åˆ›å»º MCTS+LLM Agent
agent = MCTSLLMAgent(
    name="MCTS-Agent",
    model="gpt-4o",
    api_url=API_URL,
    api_key=API_KEY,
    simulations=50,          # æ¯æ­¥è¿›è¡Œ50æ¬¡MCTSæ¨¡æ‹Ÿ
    exploration_weight=1.41, # UCBæ¢ç´¢æƒé‡
    use_llm_eval=True,       # ä½¿ç”¨LLMè¯„ä¼°ï¼ˆvséšæœºæ¨¡æ‹Ÿï¼‰
)

# é€‰æ‹©è½å­
action = agent.choose_action(env, is_white=False)
```

### è¿è¡Œæ¼”ç¤º

```bash
# Demo 1: MCTS+LLM vs åŸºç¡€LLM
python run_mcts_demo.py --demo 1 --simulations 30

# Demo 2: MCTS+LLM vs MCTS(éšæœºæ¨¡æ‹Ÿ)
python run_mcts_demo.py --demo 2 --simulations 30

# Demo 3: MCTS+LLM vs MCTS+LLM
python run_mcts_demo.py --demo 3 --simulations 50

# è¿è¡ŒåŸºå‡†æµ‹è¯•ï¼ˆå¤šå±€å¯¹å¼ˆï¼‰
python run_mcts_demo.py --benchmark --num-games 5 --simulations 30
```

### å‚æ•°è¯´æ˜

- `--demo`: é€‰æ‹©æ¼”ç¤ºæ¨¡å¼ (1/2/3)
- `--model`: æŒ‡å®šLLMæ¨¡å‹ (é»˜è®¤: gpt-4o)
- `--simulations`: MCTSæ¨¡æ‹Ÿæ¬¡æ•° (é»˜è®¤: 30)
  - æ›´å¤šæ¨¡æ‹Ÿ â†’ æ›´å¼ºä½†æ›´æ…¢
  - å»ºè®®èŒƒå›´: 20-100
- `--benchmark`: è¿è¡Œå¤šå±€å¯¹å¼ˆæµ‹è¯•
- `--num-games`: åŸºå‡†æµ‹è¯•å±€æ•° (é»˜è®¤: 3)

## æ ¸å¿ƒç‰¹æ€§

### 1. æ™ºèƒ½å‰ªæ
- ä¼˜å…ˆæ¢ç´¢å·²æœ‰æ£‹å­é™„è¿‘çš„ä½ç½®ï¼ˆ2æ ¼å†…ï¼‰
- é™åˆ¶å€™é€‰èµ°æ³•æ•°é‡ï¼Œæé«˜æœç´¢æ•ˆç‡
- ç©ºæ£‹ç›˜æ—¶ä»ä¸­å¿ƒåŒºåŸŸå¼€å§‹

### 2. LLMè¯„ä¼°ç¼“å­˜
- ç¼“å­˜LLMè¯„ä¼°ç»“æœï¼Œé¿å…é‡å¤è°ƒç”¨
- æ˜¾è‘—é™ä½APIæˆæœ¬å’Œå“åº”æ—¶é—´

### 3. é²æ£’æ€§ä¿è¯
- UCBé€‰æ‹©ä¿è¯æ¯ä¸ªèŠ‚ç‚¹éƒ½ä¼šè¢«è®¿é—®
- é™çº§ç­–ç•¥ï¼šLLMå¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤è¯„åˆ†
- æœ€ç»ˆé€‰æ‹©æœ€å¤šè®¿é—®çš„å­èŠ‚ç‚¹ï¼ˆæœ€å¯é ï¼‰

### 4. è¯¦ç»†æ—¥å¿—
```
[MCTS-Agent] Running MCTS with 50 simulations...
  Completed 10/50 simulations...
  Completed 20/50 simulations...
  ...
[MCTS-Agent] MCTS complete in 12.34s
  Best move: (7, 8)
  Visits: 28, Win rate: 0.723
```

## æ€§èƒ½åˆ†æ

### è®¡ç®—å¤æ‚åº¦

- **æ—¶é—´å¤æ‚åº¦**: O(S Ã— D)
  - S: æ¨¡æ‹Ÿæ¬¡æ•°
  - D: å¹³å‡æœç´¢æ·±åº¦
  
- **ç©ºé—´å¤æ‚åº¦**: O(B Ã— D)
  - B: åˆ†æ”¯å› å­ï¼ˆå€™é€‰èµ°æ³•æ•°ï¼‰
  - D: æœç´¢æ·±åº¦

### æ¨èé…ç½®

| åœºæ™¯ | simulations | exploration_weight | é¢„è®¡ç”¨æ—¶/æ­¥ |
|------|-------------|-------------------|-------------|
| å¿«é€Ÿæµ‹è¯• | 10-20 | 1.41 | 3-5ç§’ |
| æ­£å¸¸å¯¹å¼ˆ | 30-50 | 1.41 | 8-15ç§’ |
| å¼ºåŠ›æ¨¡å¼ | 80-100 | 1.0 | 25-40ç§’ |

## ç†è®ºèƒŒæ™¯

### MCTSçš„ä¼˜åŠ¿
1. **ä¸éœ€è¦å¯å‘å¼å‡½æ•°** - é€šè¿‡éšæœºæ¨¡æ‹Ÿå­¦ä¹ 
2. **ä»»ä½•æ—¶é—´ç®—æ³•** - å¯ä»¥éšæ—¶ä¸­æ–­å¹¶ç»™å‡ºå½“å‰æœ€ä¼˜è§£
3. **æ¸è¿‘æœ€ä¼˜** - éšç€æ¨¡æ‹Ÿæ¬¡æ•°å¢åŠ é€¼è¿‘æœ€ä¼˜ç­–ç•¥

### LLMå¢å¼ºçš„ä»·å€¼
1. **é¢†åŸŸçŸ¥è¯†æ³¨å…¥** - LLMç†è§£äº”å­æ£‹æˆ˜æœ¯ï¼ˆå¦‚"æ´»ä¸‰"ã€"çœ ä¸‰"ï¼‰
2. **æ›´å‡†ç¡®çš„è¯„ä¼°** - æ¯”éšæœºæ¨¡æ‹Ÿæ›´æ¥è¿‘çœŸå®å±€é¢ä»·å€¼
3. **æ”¶æ•›é€Ÿåº¦** - éœ€è¦æ›´å°‘çš„æ¨¡æ‹Ÿæ¬¡æ•°è¾¾åˆ°ç›¸åŒæ•ˆæœ

## æ‰©å±•æ–¹å‘

### å·²å®ç° âœ…
- [x] åŸºç¡€MCTSæ¡†æ¶
- [x] LLMå±€é¢è¯„ä¼°
- [x] UCBé€‰æ‹©ç­–ç•¥
- [x] æ™ºèƒ½å‰ªæ
- [x] è¯„ä¼°ç¼“å­˜

### æœªæ¥å·¥ä½œ ğŸš€
- [ ] å¹¶è¡ŒMCTSï¼ˆå¤šçº¿ç¨‹æœç´¢ï¼‰
- [ ] ç¥ç»ç½‘ç»œæ›¿ä»£LLMï¼ˆæ›´å¿«çš„è¯„ä¼°ï¼‰
- [ ] RAVE (Rapid Action Value Estimation)
- [ ] å±€éƒ¨æœç´¢ä¼˜åŒ–
- [ ] å¼€å±€åº“é›†æˆ
- [ ] æ®‹å±€æ•°æ®åº“

## å®éªŒç»“æœï¼ˆç¤ºä¾‹ï¼‰

```
å®éªŒè®¾ç½®:
- MCTS+LLM: 30æ¬¡æ¨¡æ‹Ÿ/æ­¥
- Baseline LLM: ç›´æ¥promptå†³ç­–
- æ¨¡å‹: GPT-4o
- å¯¹å±€æ•°: 5å±€

ç»“æœ:
- MCTS+LLM èƒœ: 4å±€
- Baseline èƒœ: 0å±€
- å¹³å±€: 1å±€

èƒœç‡: 80% (4/5)
å¹³å‡ç”¨æ—¶: 10ç§’/æ­¥ vs 1ç§’/æ­¥
```

## æŠ€æœ¯ç»†èŠ‚

### MCTSNode ç±»
```python
class MCTSNode:
    state: Tuple[Set, Set, Move, bool]  # (ç™½æ£‹, é»‘æ£‹, ä¸Šä¸€æ­¥, è½®æ¬¡)
    visits: int                          # è®¿é—®æ¬¡æ•°
    value: float                         # ç´¯ç§¯ä»·å€¼
    children: List[MCTSNode]            # å­èŠ‚ç‚¹
    untried_moves: List[Move]           # æœªå°è¯•çš„èµ°æ³•
```

### LLMPositionEvaluator ç±»
```python
class LLMPositionEvaluator:
    def evaluate_position(white, black, perspective) -> float:
        """
        è¾“å…¥: æ£‹ç›˜çŠ¶æ€ + è¯„ä¼°è§†è§’
        è¾“å‡º: [0, 1] èŒƒå›´çš„è¯„åˆ†
        
        è€ƒè™‘å› ç´ :
        - ç›´æ¥å¨èƒ (4è¿ã€æ´»3)
        - ä¸­å¿ƒæ§åˆ¶
        - æ½œåœ¨è¿æ¥
        - é˜²å®ˆéœ€æ±‚
        """
```

## å‚è€ƒæ–‡çŒ®

1. Browne et al. (2012). "A Survey of Monte Carlo Tree Search Methods"
2. Silver et al. (2016). "Mastering the game of Go with deep neural networks and tree search"
3. Anthropic (2024). "Constitutional AI: Harmlessness from AI Feedback"

## è´¡çŒ®è€…

- å®ç°è€…: [Your Name]
- æ—¥æœŸ: 2025-12-22
- åˆ†æ”¯: feature/mcts-llm-agent

## License

æœ¬é¡¹ç›®éµå¾ªåŸä»“åº“çš„å¼€æºåè®®ã€‚

---

**Happy Playing! ğŸ®ğŸ¤–**

